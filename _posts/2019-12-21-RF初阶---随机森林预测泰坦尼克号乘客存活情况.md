---
title: RF初阶---随机森林预测泰坦尼克号乘客存活情况
categories: ML     
date: 2019-12-21 10:56:11
---
数据集来源于kaggle(著名的机器学习数据下载中心)，Titanic数据集包括三个csv文件，分别是训练数据集，测试数据集和测试结果集。
---

```python
#coding=utf-8
#20191220
#Author:wuqifan
#随机森林

from sklearn import preprocessing
from sklearn.preprocessing import Imputer
from sklearn.metrics import accuracy_score

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import seaborn as sns
from sklearn import  model_selection            #sklearn在新版本已经抛弃cross_validation，改成model_selection
import pandas as pd

# 加载数据
##### 加载训练和测试数据
#####--------------------------------------------------------------------------------------------------
#这里读入数据的时候我们没有做任何的处理（像去除空值这些）
train = pd.read_csv("./Titanic_Dataset/train.csv",dtype={"Age":np.float64},)
test = pd.read_csv("./Titanic_Dataset/test.csv",dtype={"Age":np.float64},)

#查看样本数和特征数
# train_num,train_var_num=np.shape(train)
# test_num,test_var_num=np.shape(test)
# print("训练集：有",train_num,"个样本","每个样本有",train_var_num,"个变量.")
# print("测试集：有",test_num,"个样本","每个样本有",test_var_num,"个变量.")
# print(train.info())       #查看数据的缺失情况
# print(test.info())
# print(train.describe())     #查看数据的描述性信息（总数，均值，方差，最大最小值等）

# ------------------------------------------------绘图------------------------------------------------------
#------------我们要通过绘图来观察训练数集的基本情况哦，我们先从登舱口Embarked开始,来绘制二维柱状图，不同性别在不同登舱口的生存情况
# sns.barplot(x='Embarked',y='Survived',hue='Sex',data=train)         #可见，无论哪个港口上岸，星星获救的概率高出男性。至于哪个港口上船的生存率较高还看不出来

#------------接着，我们用折线图从Pclass，也就是几等舱来观测下生存概率
# sns.pointplot(x='Pclass',y='Survived',hue='Sex',data=train,palette={'male':'blue','female':'pink'},
#              marker=['*',"o"],linestyle=['-','--'])     #随着等级舱的降低，不论是男性或女性，获救率也在降低。所以可能Pclass也对Surived有显著影响

# -----------除此之外，我们来看看 堂兄弟/妹，孩子/父母有几人，对是否获救的影响
# SibSp_info = train.groupby(['SibSp','Survived'])
# SibSp_df = pd.DataFrame(SibSp_info.count()['PassengerId'])
# print(SibSp_df)
#
# Parch_info = train.groupby(['Parch','Survived'])
# Parch_df = pd.DataFrame(Parch_info.count()['PassengerId'])
# print(Parch_df)
# 只能说，大部分的人并没有携带一家老小都来坐船玩,暂时看不出，SibSp、Parch对Survived的影响。先不管它


#
# # 简化年龄，即对年龄进行分组
# def simplify_ages(df):
#     #补上缺失值，方便分组
#     df.Age = df.Age.fillna(-0.5)
#     # 把不同Age分成不同的区间，[-1,0],[1,5],[6-12]....,60以上，放到bins里，八个区间，对应八个区间名称在group_names
#     bins = (-1,0,5,12,18,25,35,60,120)
#     group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']
#     #开始对数据进行离散化，pandas.cut就是这个功能
#     catagories = pd.cut(df.Age, bins, labels=group_names)
#     df.Age = catagories
#     return df
#
# # 简化Cabin，就是取字母
# def simplify_cabin(df):
#     df.Cabin = df.Cabin.fillna('N')
#     df.Cabin = df.Cabin.apply(lambda x:x[0])
#     return df
#
# # 简化工资，也就是分组
# def simplify_fare(df):
#     df.Fare = df.Fare.fillna(-0.5)
#     bins = (-1, 0, 8, 15, 31, 1000)
#     group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']
#     catagories = pd.cut(df.Fare,bins,labels=group_names)
#     df.Fare = catagories
#     return df
#
# # 删除无用信息
# def simplify_drop(df):
#     return df.drop(['Name','Ticket','Embarked'],axis=1)
#
# def transform_features(df):
#     df = simplify_ages(df)
#     df = simplify_cabin(df)
#     df = simplify_fare(df)
#     df = simplify_drop(df)
#     return df
#
# data_train = transform_features(train)
# data_test = transform_features(test)
#
# # 对年龄等离散变量进行变换后，继续画图
# sns.barplot(x = 'Age',y = 'Survived',hue='Sex',data = data_train)       #老人小孩获救率最高，中青年特别是男性，获救率是最低的。真的是很绅士了。

#再按Cabin-Survived画，根据舱位，其实也可以看出一些端倪哦
# sns.barplot(x = 'Cabin',y = 'Survived',hue='Sex',data = data_train)

#按照Fare进行画图
# sns.barplot(x = 'Fare',y = 'Survived',hue='Sex',data = data_train)      #果然票费越高的，存活率更高啊
# ---------------------------------------------------以上部分为数据介绍----------------------------------------------


# 数据预处理----将缺失值进行处理填充，并对Sex，Embarked转换为数值
def harmonize_data(titanic):
    titanic["Age"] = titanic["Age"].fillna(titanic["Age"].median())     #用年龄的中位数填充缺失值
    titanic.loc[titanic["Sex"] == "male","Sex"] = 0
    titanic.loc[titanic["Sex"] == "female","Sex"] = 1
    titanic["Embarked"] = titanic["Embarked"].fillna("S")       #对缺失的Embarked值补S
    titanic.loc[titanic["Embarked"] == "S","Embarked"] = 0
    titanic.loc[titanic["Embarked"] == "C","Embarked"] = 1
    titanic.loc[titanic["Embarked"] == "Q","Embarked"] = 2
    titanic["Fare"] = titanic["Fare"].fillna(titanic["Fare"].median())
    return titanic

train_data = harmonize_data(train)
test_data = harmonize_data(test)

#变量间的关系可能会对模型的效果有影响，实际中可以通过变量组合及相关性分析等确定模型的特征,这里取7个特征作为有效特征
predictors = ["Pclass","Sex","Age","SibSp","Parch","Fare","Embarked"]
'''#random_state 控制随机状态，保证每次取随机结果相同，如果，对随机状态不加控制，那么实验的结果就无法固定，而是随机的显现。
n_estimators 树的数量  ；
min_samples_split 分裂所需的最小样本数 ；
min_samples_leaf ; 叶节点最小样本数。

'''

alg = RandomForestClassifier(
    random_state=1,
    n_estimators=150,
    min_samples_leaf=2,
    min_samples_split=4)

# 交叉验证，目的是对模型性能度量，把每一折都当做一次测试集，其余九折当成训练集，这样循环10次，即10折交叉验证法，对模型的分类精度进行平均。
scores = model_selection.cross_val_score(
    alg,
    train_data[predictors],
    train_data["Survived"],
    cv=5)
print('K折交叉验证的模型精度为{}'.format(scores.mean()))
print('K折交叉验证的模型标准差为{}'.format(scores.std()))

'''cross_val_score(estimator, 
                X,      X ：特征数组 
                y=None,     y : 标签数组 
                groups=None,        groups:如果数据需要分组采样的话 
                scoring=None,       scoring ：评价函数 
                cv=None,        cv：交叉验证的k值即k折，当输入为整数或者是None,估计器是分类器，y是二分类或者多分类，采用StratifiedKFold 进行数据划分 
                verbose=0, 
                fit_params=None,    fit_params：字典，将估计器中fit方法的参数通过字典传递
                pre_dispatch='2*n_jobs')
'''

# 预测结果输出,除了用交叉验证方法对分类精度进行评估外，还可以通过以下函数对测试结果进行输出，输出结果存储在文件“run-01.csv中”
test_data_true = pd.read_csv("./Titanic_Dataset/gender_submission.csv")
def create_submission(alg,train,test,predictors,filename):
    alg.fit(train[predictors],train["Survived"])
    predictions = alg.predict(test[predictors])
    print('使用RF预测精度为:{}'.format(accuracy_score(test_data_true["Survived"], predictions)))        #输出精度
    submission = pd.DataFrame({"PassengerId":test["PassengerId"],"Survived":predictions})
    submission.to_csv(filename,index=False)
create_submission(alg,train_data,test_data,predictors,"应用RF对Titanic数据进行预测结果.csv")
print("OK,Everything has been down")
```
